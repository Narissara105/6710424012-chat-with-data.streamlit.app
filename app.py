import streamlit as st
import pandas as pd
import google.generativeai as genai
import numpy as np
import datetime
from dateutil import parser as dateparser
import math
import re

try:
    from rapidfuzz import process
except ModuleNotFoundError:
    process = None

# -------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î CSV ‡πÅ‡∏ö‡∏ö‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô
# -------------------------------
def load_flexible_csv(uploaded_file):
    tried_encodings = ["utf-8", "utf-8-sig", "iso-8859-1", "windows-874"]
    delimiters = [",", ";", "\t", "|"]
    for encoding in tried_encodings:
        for sep in delimiters:
            try:
                df = pd.read_csv(
                    uploaded_file,
                    encoding=encoding,
                    sep=sep,
                    engine="python",
                    skipinitialspace=True,
                    na_values=["", "NA", "N/A", "-", "--", "null"],
                    keep_default_na=True
                )
                if df.shape[1] >= 2:
                    return df
            except Exception:
                continue
    raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡πÑ‡∏î‡πâ")

# -------------------------------
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Gemini
# -------------------------------
st.set_page_config(page_title="Chat with Data ü§ñ", layout="wide")
st.title("ü§ñ My Chatbot and Data Analysis App")
st.subheader("‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢) ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£")

key = st.secrets["gemini_api_key"]
genai.configure(api_key=key)
model = genai.GenerativeModel("gemini-2.0-flash-lite")

# -------------------------------
# Session State
# -------------------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "uploaded_data" not in st.session_state:
    st.session_state.uploaded_data = None
if "uploaded_dictionary" not in st.session_state:
    st.session_state.uploaded_dictionary = None
if "analyze_data_checkbox" not in st.session_state:
    st.session_state.analyze_data_checkbox = False
if "qa_memory" not in st.session_state:
    st.session_state.qa_memory = {}

# -------------------------------
# Upload Files
# -------------------------------
uploaded_file = st.file_uploader("\U0001F4C1 ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", type=["csv"])
if uploaded_file:
    try:
        df = load_flexible_csv(uploaded_file)
        st.session_state.uploaded_data = df
        st.success("‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        st.write("### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        st.dataframe(df.head())
        st.session_state.analyze_data_checkbox = True
    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {e}")

uploaded_dict = st.file_uploader("\U0001F4C4 ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Data Dictionary (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)", type=["csv"])
if uploaded_dict:
    try:
        dictionary_df = pd.read_csv(uploaded_dict)
        st.session_state.uploaded_dictionary = dictionary_df
        st.success("‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Data Dictionary ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        with st.expander("üìã ‡πÅ‡∏™‡∏î‡∏á Data Dictionary"):
            st.dataframe(dictionary_df)
    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô Dictionary: {e}")

# -------------------------------
# Checkbox ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI
# -------------------------------
analyze_data_checkbox = st.checkbox("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ AI", value=st.session_state.analyze_data_checkbox)

# -------------------------------
# Show Chat History
# -------------------------------
for role, message in st.session_state.chat_history:
    avatar = "üôÇ" if role == "user" else "ü§ñ"
    with st.chat_message(role, avatar=avatar):
        st.markdown(message)

# -------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)
# -------------------------------
def summarize_as_analyst(answer: str) -> str:
    summary_prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î Python ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DataFrame ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)

**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:** {question}

**‡∏ä‡∏∑‡πà‡∏≠ DataFrame:** {df_name}
**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:**
{data_dict_text}
**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 2 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å:**
{example_record}
{dict_text}

**‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**
- ‡πÉ‡∏ä‡πâ exec() ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
- ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô datetime ‡∏î‡πâ‡∏ß‡∏¢ pd.to_datetime()
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤ ANSWER ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö, ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠ + ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
- ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ñ‡∏≤‡∏°‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏° ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏£‡∏ß‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
- ‡∏´‡πâ‡∏≤‡∏° import pandas ‡∏´‡∏£‡∏∑‡∏≠ datetime
- ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏≥‡∏´‡∏ô‡∏î
- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
"""

            code_response = model.generate_content(prompt)
            raw_code = code_response.text
            match = re.search(r"```python(.*?)```", raw_code, re.DOTALL)
            generated_code = match.group(1).strip() if match else raw_code.strip()

            local_vars = {
                df_name: df.copy(),
                "df": df,
                "data": df,
                "pd": pd,
                "datetime": datetime,
                "dt": pd.to_datetime,
                "np": np,
                "math": math,
                "dateparser": dateparser,
                "__builtins__": __builtins__,
                "datetim": datetime,
                "dateime": datetime,
                "dtt": pd.to_datetime,
                "datetime_module": datetime,
                "datetime_now": datetime.datetime.now,
            }

            exec(generated_code, {}, local_vars)
            answer = local_vars.get("ANSWER", "No variable named 'ANSWER' was created.")

            if isinstance(answer, pd.DataFrame):
                answer_text = answer.head(5).to_string(index=False)
            else:
                answer_text = str(answer)

            bot_response = summarize_as_analyst(answer_text)

            styled_bot_response = bot_response
            st.session_state.qa_memory[normalized_question] = styled_bot_response
            st.chat_message("assistant", avatar="ü§ñ").markdown(styled_bot_response, unsafe_allow_html=True)
            st.session_state.chat_history.append(("assistant", styled_bot_response))

        elif not analyze_data_checkbox:
            bot_response = "üìå ‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô"
            st.chat_message("assistant", avatar="ü§ñ").markdown(bot_response)
        else:
            bot_response = "üìÇ ‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"
            st.chat_message("assistant", avatar="ü§ñ").markdown(bot_response)

    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

